{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc326d2c-d823-4140-9e75-5ddbf5425459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --quiet pytorch_lightning\n",
    "# !pip install --quiet transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7058c01a-823d-4583-97c8-4571d7832018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82c511e-b764-474d-8265-e1985b5a4a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import textwrap\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from transformers import(\n",
    "    AdamW,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8fcd511-a8bc-48e8-a9dd-00aa75375cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee13b38-d892-4924-9c29-5cf47a331c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78fdfac-ab48-405d-8d8d-8180deef6314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0948d8f6-a36e-42a7-92a0-5db1001b048a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_device_and_set_seed(seed):\n",
    "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    return device\n",
    "    \n",
    "SEED = 123\n",
    "device = get_device_and_set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1cd4bd-9a42-4b13-9cac-3d3a13513cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ffff4-898c-47dc-953e-65fc985a1743",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load origin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08bd429-b4d4-4051-9981-f4229782c766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-base\", load_in_8bit=True, device_map=\"auto\")\n",
    "# model.to(device)\n",
    "print(next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f66f0df-fb15-46ac-ad1c-9262f223f96a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/nghiatl/anaconda3/envs/chatgpt/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\", use_fast = True) \n",
    "labels = tokenizer(\n",
    "        'tôi thích bạn', max_length=256, truncation=True, padding=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a84b1c-b45e-4639-8d18-5c783c58408c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁tô', 'i', '▁th', 'ích', '▁b', 'ạn', '</s>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(labels['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31dcfd-d816-4484-a673-cac97e852e76",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492c52cf-2cdb-4dec-86db-df658dbb653c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = './data/address_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03f8e78-ede8-421d-bf08-53b1e5f5b1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_address</th>\n",
       "      <th>filter_address</th>\n",
       "      <th>mistake_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thửa đất số 11, Tờ bản đồ số 39, Ấp Hoàng Việt...</td>\n",
       "      <td>Xã Tân Phước, Huyện Tân Hồng, Tỉnh Đồng Tháp</td>\n",
       "      <td>Thửa đất số11 Tờbản đồ số 39 p Hoàng Việt Xã T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Số 27, Đường Thiên Hộ Dương, Khóm 3, Phường An...</td>\n",
       "      <td>Đường Thiên Hộ Dương, Phường An Thạnh, Thành p...</td>\n",
       "      <td>số 27 đường thiên hộ dương khóm 3 phường an th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tổ 20, Khóm An Lợi, Phường An Bình A, Thành ph...</td>\n",
       "      <td>Phường An Bình A, Thành phố Hồng Ngự, Tỉnh Đồn...</td>\n",
       "      <td>To 20 Khom An Lợi Phường An Binh A Thành phố H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thôn Thiếp Trì, Xã Thái Đào, Huyện Lạng Giang,...</td>\n",
       "      <td>Xã Thái Đào, Huyện Lạng Giang, Tỉnh Bắc Giang</td>\n",
       "      <td>thôn thiếp trì xã thái đào huyện lạng giang tỉ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Số nhà 335 đường Trường Chinh, Thị Trấn Thắng,...</td>\n",
       "      <td>đường Trường Chinh, Thị Trấn Thắng, Huyện Hiệp...</td>\n",
       "      <td>ố nhà 335 đường Trưng Chinh, Thị rấn Thắng, Hu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       input_address  \\\n",
       "0  Thửa đất số 11, Tờ bản đồ số 39, Ấp Hoàng Việt...   \n",
       "1  Số 27, Đường Thiên Hộ Dương, Khóm 3, Phường An...   \n",
       "2  Tổ 20, Khóm An Lợi, Phường An Bình A, Thành ph...   \n",
       "3  Thôn Thiếp Trì, Xã Thái Đào, Huyện Lạng Giang,...   \n",
       "4  Số nhà 335 đường Trường Chinh, Thị Trấn Thắng,...   \n",
       "\n",
       "                                      filter_address  \\\n",
       "0       Xã Tân Phước, Huyện Tân Hồng, Tỉnh Đồng Tháp   \n",
       "1  Đường Thiên Hộ Dương, Phường An Thạnh, Thành p...   \n",
       "2  Phường An Bình A, Thành phố Hồng Ngự, Tỉnh Đồn...   \n",
       "3      Xã Thái Đào, Huyện Lạng Giang, Tỉnh Bắc Giang   \n",
       "4  đường Trường Chinh, Thị Trấn Thắng, Huyện Hiệp...   \n",
       "\n",
       "                                     mistake_address  \n",
       "0  Thửa đất số11 Tờbản đồ số 39 p Hoàng Việt Xã T...  \n",
       "1  số 27 đường thiên hộ dương khóm 3 phường an th...  \n",
       "2  To 20 Khom An Lợi Phường An Binh A Thành phố H...  \n",
       "3  thôn thiếp trì xã thái đào huyện lạng giang tỉ...  \n",
       "4  ố nhà 335 đường Trưng Chinh, Thị rấn Thắng, Hu...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(train_path)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958f8824-adca-48bd-ab79-c1af9f86e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = data_df[:500000]\n",
    "# data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b9d858a-db06-4ffc-9840-51b91ba49d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c59b959-152a-4fe5-8d7f-dfe5113b033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b035ec2f-7c22-498e-8df3-42a5cd10795c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd1d3bd-42f4-4f86-9508-e31b5e09264b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples, padding=\"max_length\"):\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"inputs\"], max_length=256, truncation=True, padding=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(\n",
    "        examples[\"labels\"], max_length=256, truncation=True, padding=True\n",
    "    )\n",
    "    \n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "        \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    model_inputs['input_ids'] = model_inputs['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5841ab54-9900-42fa-886c-b97ea4d7bbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict_obj = {'inputs': train_df['mistake_address'], 'labels': train_df['filter_address']}\n",
    "# dataset = Dataset.from_dict(dict_obj)\n",
    "# dataset = dataset.train_test_split(test_size=0.1)\n",
    "# train_data = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f5c5c7-23dd-4184-b398-89036d6894d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_obj = {'inputs': test_df['mistake_address'], 'labels': test_df['mistake_address']}\n",
    "dataset = Dataset.from_dict(dict_obj)\n",
    "test_data = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5175dc3-d33f-4fe7-a3ff-314cf3c712ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['train'].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c4f0e-b320-4c8a-9778-3cadfec4d3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0049e7f-c450-4d12-b0b8-62fee5668c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, pad_to_multiple_of=8, return_tensors=\"pt\")\n",
    "data_collator([train_data['train'].__getitem__(2)])['labels'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab778de-7a6d-42b8-a416-efc9771abc54",
   "metadata": {},
   "source": [
    "## PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cff8cf85-06b7-45dd-932e-81602c462c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1769472 || all params: 584170752 || trainable%: 0.3029032169005271\n"
     ]
    }
   ],
   "source": [
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    " r=16,\n",
    " lora_alpha=8,\n",
    " target_modules=[\"q\", \"v\"],\n",
    " lora_dropout=0.05,\n",
    " bias=\"none\",\n",
    " task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "# prepare int-8 model for training\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85e3c6eb-95ae-442a-a22a-2ae5204b76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    \"T5_address_model/\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.05,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    logging_dir='./log',\n",
    "    group_by_length=True,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f543e68-3b8b-480f-b560-2c3f83ac2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"lora_T5_address_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6686e00a-1770-48b6-b130-903dec96fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"lora_T5_address_model/\",\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=8,\n",
    "    # gradient_accumulation_steps=4, \n",
    "    learning_rate=1e-4, # higher learning rate\n",
    "    num_train_epochs=10,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps = 100,\n",
    "    group_by_length=True,\n",
    "    save_strategy='epoch',\n",
    "    # load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "453e94ce-7c21-4f85-a1f7-f6d327059727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101250.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[\"train\"]) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50c518d3-89c7-4fd4-b687-c4a2ca00db5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d28878-92c2-46d7-b44f-09baeb753a52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "251422d9-884a-418a-93f9-89c2e6db0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8867e-c435-400e-8eeb-1c709b372255",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlenghia11a4\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/nghiatl/ADDRESS/address_model/wandb/run-20231205_022432-s9raqd8q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lenghia11a4/huggingface/runs/s9raqd8q' target=\"_blank\">rich-forest-15</a></strong> to <a href='https://wandb.ai/lenghia11a4/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lenghia11a4/huggingface' target=\"_blank\">https://wandb.ai/lenghia11a4/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lenghia11a4/huggingface/runs/s9raqd8q' target=\"_blank\">https://wandb.ai/lenghia11a4/huggingface/runs/s9raqd8q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nghiatl/anaconda3/envs/chatgpt/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/nghiatl/anaconda3/envs/chatgpt/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28768' max='506250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 28768/506250 5:51:24 < 97:12:59, 1.36 it/s, Epoch 0.57/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data[\"train\"],\n",
    "    eval_dataset=train_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370775cc-b658-4e45-90ee-e53959d5688c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55c24e3d-b452-4901-8ef6-acddfb6d995d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"merge_lora_t5_1\", torch_dtype=torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "964138c9-db0d-46c1-a6a1-2ad281849317",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-base\", torch_dtype=torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "621454f9-2646-43dc-b847-cf052ec449bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6554ca1-3583-4211-93bd-f7d1455d931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = './lora_T5_address_model/checkpoint-183458'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52e5db5b-68e0-4d53-aa7f-ee1871421893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ada5210-e479-4c4b-837f-339b3bb5097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a355e3e9-6b05-4133-9fa3-9d55d9d5e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a208463e-111e-4181-82b7-b9ed28c102e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.data = param.data.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf0845b5-915d-40c8-bda9-e8f71ee3567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('merge_lora_t5_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e67a7b-291f-42a0-b047-d398c901c9df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c739f66-c46e-4a2c-a933-d04f8918bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc2c1000-4195-4a1a-b960-5a357ba9abd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SN 172C đường Minh Lang, Phường Tin Cát,Thàn phố Vit Trì, Phú Thọ'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 9\n",
    "test_df.iloc[idx]['mistake_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6669ace2-0412-45fe-b5b9-6c2179880914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'đường Minh Lang, Phường Tiên Cát, Thành phố Việt Trì,  Phú Thọ'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[idx]['filter_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "40de6abb-3b63-4565-89c6-6152c63c33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[0]['mistake_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "14d733d5-d3f7-4652-bf18-024def42c144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  355,  2241, 47314,   320,  2238,   690,  2241,   366,  1534,   320,\n",
       "          2238,   394,  3255,   690,  1263,   259, 19404,  1824,   471,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t = test_df.iloc[idx]['mistake_address']\n",
    "t = 'đường Lam Sơn phường Tân Sơn thành phố Thanh Hoá'\n",
    "b = tokenizer(t, return_tensors='pt')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "34df80a1-ea47-405e-ace9-f8127bb1530d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  đường Lam Sơn phường Tân Sơn thành phố Thanh Hoá\n",
      "Prediction times:  0.5218467712402344\n",
      "Output:  đường Lam Sơn, Phường Tân Sơn, Thành phố Thanh Hóa, Thanh Hóa\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print('Input: ', t)\n",
    "st = time.time()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "          input_ids=b['input_ids'].to('cuda'),\n",
    "          max_length=256,\n",
    "          attention_mask=b['attention_mask'].to('cuda'),\n",
    "      )\n",
    "end = time.time() - st\n",
    "print('Prediction times: ', end)\n",
    "print('Output: ', tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0084225-e4ca-4e1b-a16a-967dabefda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78536f42-ae29-438b-8d59-90b08398f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     print(param.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0666ed-0dc0-406a-86ca-da09ad515e2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "409e71cb-e4fc-427c-84ba-f5a7fa18de80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d115eb4-8da6-4cc4-8b1e-98d584710793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.23835126750408075,\n",
       " 'rouge2': 0.14379510590522415,\n",
       " 'rougeL': 0.2161130252997705,\n",
       " 'rougeLsum': 0.21546445876754589}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch \n",
    "import numpy as np\n",
    "metrics = rouge\n",
    "\n",
    "max_target_length = 256\n",
    "dataloader = torch.utils.data.DataLoader(test_data, collate_fn=data_collator, batch_size=32)\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "for i, batch in enumerate(dataloader):\n",
    "  outputs = model.generate(\n",
    "      input_ids=batch['input_ids'].to('cuda'),\n",
    "      max_length=max_target_length,\n",
    "      attention_mask=batch['attention_mask'].to('cuda'),\n",
    "  )\n",
    "  outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n",
    "\n",
    "  labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n",
    "  actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n",
    "  predictions.extend(outputs)\n",
    "  references.extend(actuals)\n",
    "  metrics.add_batch(predictions=outputs, references=actuals)\n",
    "\n",
    "\n",
    "metrics.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2873f01-6ffe-4fef-be54-e50813fd251a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5341"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "correct += sum(o==a for o, a in zip(predictions, references))\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c3487f8-1c09-4524-98af-0de00cf46053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945996275605214"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/ len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1888f79-ee5d-4932-be10-b4306c00e625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nguyễn văn tiến'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e90c77fc-664c-44e8-857e-1b16eb7ce516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nguyễn văn tiến'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71cec75a-de54-4d82-a4a8-c455d25ff749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a= next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c92be36-98b7-406d-ac84-5fc81bdd2113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nguyễn văn tiến thì dạ bên không cho'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(a['input_ids'][0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt-env",
   "language": "python",
   "name": "chatgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
